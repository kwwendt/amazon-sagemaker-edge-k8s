{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Edge Manager Demo Notebook\n",
    "\n",
    "**SageMaker Studio Kernel**: Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)\n",
    "\n",
    "In this demo, we will compile a pre-trained YoloV4 model using **Amazon SageMaker Neo** and package the model for deployment via **Amazon SageMaker Edge Manager**. This notebook has the following steps:\n",
    " - Generate the pre-trained model and upload it to **Amazon S3**\n",
    " - Generate IoT credentials required by the Agent\n",
    " - Generate the config file required by the Agent\n",
    " - Create and upload the full agent deployment package to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries and declare dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pillow pycocotools\n",
    "!apt-get -y update && apt-get -y install build-essential procps\n",
    "!pip install -U numpy sysv_ipc grpcio-tools grpcio protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -q --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "import os\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate pre-trained YoloV4 model\n",
    "\n",
    "We will be using the following PyTorch implementation of YoloV4 for Object Detection and Classification: https://github.com/Tianxiaomo/pytorch-YOLOv4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Mish(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * (torch.tanh(torch.nn.functional.softplus(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Upsample, self).__init__()\n",
    "\n",
    "    def forward(self, x, target_size, inference=False):\n",
    "        assert (x.data.dim() == 4)\n",
    "\n",
    "        if inference:\n",
    "\n",
    "            return x.view(x.size(0), x.size(1), x.size(2), 1, x.size(3), 1).\\\n",
    "                    expand(x.size(0), x.size(1), x.size(2), target_size[2] // x.size(2), x.size(3), target_size[3] // x.size(3)).\\\n",
    "                    contiguous().view(x.size(0), x.size(1), target_size[2], target_size[3])\n",
    "        else:\n",
    "            return F.interpolate(x, size=(target_size[2], target_size[3]), mode='nearest')\n",
    "\n",
    "\n",
    "class Conv_Bn_Activation(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, activation, bn=True, bias=False):\n",
    "        super().__init__()\n",
    "        pad = (kernel_size - 1) // 2\n",
    "\n",
    "        self.conv = nn.ModuleList()\n",
    "        if bias:\n",
    "            self.conv.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad))\n",
    "        else:\n",
    "            self.conv.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad, bias=False))\n",
    "        if bn:\n",
    "            self.conv.append(nn.BatchNorm2d(out_channels))\n",
    "        if activation == \"mish\":\n",
    "            self.conv.append(Mish())\n",
    "        elif activation == \"relu\":\n",
    "            self.conv.append(nn.ReLU(inplace=True))\n",
    "        elif activation == \"leaky\":\n",
    "            self.conv.append(nn.LeakyReLU(0.1, inplace=True))\n",
    "        elif activation == \"linear\":\n",
    "            pass\n",
    "        else:\n",
    "            print(\"activate error !!! {} {} {}\".format(sys._getframe().f_code.co_filename,\n",
    "                                                       sys._getframe().f_code.co_name, sys._getframe().f_lineno))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.conv:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Sequential residual blocks each of which consists of \\\n",
    "    two convolution layers.\n",
    "    Args:\n",
    "        ch (int): number of input and output channels.\n",
    "        nblocks (int): number of residual blocks.\n",
    "        shortcut (bool): if True, residual tensor addition is enabled.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ch, nblocks=1, shortcut=True):\n",
    "        super().__init__()\n",
    "        self.shortcut = shortcut\n",
    "        self.module_list = nn.ModuleList()\n",
    "        for i in range(nblocks):\n",
    "            resblock_one = nn.ModuleList()\n",
    "            resblock_one.append(Conv_Bn_Activation(ch, ch, 1, 1, 'mish'))\n",
    "            resblock_one.append(Conv_Bn_Activation(ch, ch, 3, 1, 'mish'))\n",
    "            self.module_list.append(resblock_one)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.module_list:\n",
    "            h = x\n",
    "            for res in module:\n",
    "                h = res(h)\n",
    "            x = x + h if self.shortcut else h\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownSample1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv_Bn_Activation(3, 32, 3, 1, 'mish')\n",
    "\n",
    "        self.conv2 = Conv_Bn_Activation(32, 64, 3, 2, 'mish')\n",
    "        self.conv3 = Conv_Bn_Activation(64, 64, 1, 1, 'mish')\n",
    "        # [route]\n",
    "        # layers = -2\n",
    "        self.conv4 = Conv_Bn_Activation(64, 64, 1, 1, 'mish')\n",
    "\n",
    "        self.conv5 = Conv_Bn_Activation(64, 32, 1, 1, 'mish')\n",
    "        self.conv6 = Conv_Bn_Activation(32, 64, 3, 1, 'mish')\n",
    "        # [shortcut]\n",
    "        # from=-3\n",
    "        # activation = linear\n",
    "\n",
    "        self.conv7 = Conv_Bn_Activation(64, 64, 1, 1, 'mish')\n",
    "        # [route]\n",
    "        # layers = -1, -7\n",
    "        self.conv8 = Conv_Bn_Activation(128, 64, 1, 1, 'mish')\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = self.conv1(input)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x2)\n",
    "        # route -2\n",
    "        x4 = self.conv4(x2)\n",
    "        x5 = self.conv5(x4)\n",
    "        x6 = self.conv6(x5)\n",
    "        # shortcut -3\n",
    "        x6 = x6 + x4\n",
    "\n",
    "        x7 = self.conv7(x6)\n",
    "        # [route]\n",
    "        # layers = -1, -7\n",
    "        x7 = torch.cat([x7, x3], dim=1)\n",
    "        x8 = self.conv8(x7)\n",
    "        return x8\n",
    "\n",
    "\n",
    "class DownSample2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv_Bn_Activation(64, 128, 3, 2, 'mish')\n",
    "        self.conv2 = Conv_Bn_Activation(128, 64, 1, 1, 'mish')\n",
    "        # r -2\n",
    "        self.conv3 = Conv_Bn_Activation(128, 64, 1, 1, 'mish')\n",
    "\n",
    "        self.resblock = ResBlock(ch=64, nblocks=2)\n",
    "\n",
    "        # s -3\n",
    "        self.conv4 = Conv_Bn_Activation(64, 64, 1, 1, 'mish')\n",
    "        # r -1 -10\n",
    "        self.conv5 = Conv_Bn_Activation(128, 128, 1, 1, 'mish')\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = self.conv1(input)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x1)\n",
    "\n",
    "        r = self.resblock(x3)\n",
    "        x4 = self.conv4(r)\n",
    "\n",
    "        x4 = torch.cat([x4, x2], dim=1)\n",
    "        x5 = self.conv5(x4)\n",
    "        return x5\n",
    "\n",
    "\n",
    "class DownSample3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv_Bn_Activation(128, 256, 3, 2, 'mish')\n",
    "        self.conv2 = Conv_Bn_Activation(256, 128, 1, 1, 'mish')\n",
    "        self.conv3 = Conv_Bn_Activation(256, 128, 1, 1, 'mish')\n",
    "\n",
    "        self.resblock = ResBlock(ch=128, nblocks=8)\n",
    "        self.conv4 = Conv_Bn_Activation(128, 128, 1, 1, 'mish')\n",
    "        self.conv5 = Conv_Bn_Activation(256, 256, 1, 1, 'mish')\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = self.conv1(input)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x1)\n",
    "\n",
    "        r = self.resblock(x3)\n",
    "        x4 = self.conv4(r)\n",
    "\n",
    "        x4 = torch.cat([x4, x2], dim=1)\n",
    "        x5 = self.conv5(x4)\n",
    "        return x5\n",
    "\n",
    "\n",
    "class DownSample4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv_Bn_Activation(256, 512, 3, 2, 'mish')\n",
    "        self.conv2 = Conv_Bn_Activation(512, 256, 1, 1, 'mish')\n",
    "        self.conv3 = Conv_Bn_Activation(512, 256, 1, 1, 'mish')\n",
    "\n",
    "        self.resblock = ResBlock(ch=256, nblocks=8)\n",
    "        self.conv4 = Conv_Bn_Activation(256, 256, 1, 1, 'mish')\n",
    "        self.conv5 = Conv_Bn_Activation(512, 512, 1, 1, 'mish')\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = self.conv1(input)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x1)\n",
    "\n",
    "        r = self.resblock(x3)\n",
    "        x4 = self.conv4(r)\n",
    "\n",
    "        x4 = torch.cat([x4, x2], dim=1)\n",
    "        x5 = self.conv5(x4)\n",
    "        return x5\n",
    "\n",
    "\n",
    "class DownSample5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv_Bn_Activation(512, 1024, 3, 2, 'mish')\n",
    "        self.conv2 = Conv_Bn_Activation(1024, 512, 1, 1, 'mish')\n",
    "        self.conv3 = Conv_Bn_Activation(1024, 512, 1, 1, 'mish')\n",
    "\n",
    "        self.resblock = ResBlock(ch=512, nblocks=4)\n",
    "        self.conv4 = Conv_Bn_Activation(512, 512, 1, 1, 'mish')\n",
    "        self.conv5 = Conv_Bn_Activation(1024, 1024, 1, 1, 'mish')\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = self.conv1(input)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x1)\n",
    "\n",
    "        r = self.resblock(x3)\n",
    "        x4 = self.conv4(r)\n",
    "\n",
    "        x4 = torch.cat([x4, x2], dim=1)\n",
    "        x5 = self.conv5(x4)\n",
    "        return x5\n",
    "\n",
    "\n",
    "class Neck(nn.Module):\n",
    "    def __init__(self, inference=False):\n",
    "        super().__init__()\n",
    "        self.inference = inference\n",
    "\n",
    "        self.conv1 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv2 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv3 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        # SPP\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=1, padding=5 // 2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=9, stride=1, padding=9 // 2)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=13, stride=1, padding=13 // 2)\n",
    "\n",
    "        # R -1 -3 -5 -6\n",
    "        # SPP\n",
    "        self.conv4 = Conv_Bn_Activation(2048, 512, 1, 1, 'leaky')\n",
    "        self.conv5 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv6 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv7 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        # UP\n",
    "        self.upsample1 = Upsample()\n",
    "        # R 85\n",
    "        self.conv8 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        # R -1 -3\n",
    "        self.conv9 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv10 = Conv_Bn_Activation(256, 512, 3, 1, 'leaky')\n",
    "        self.conv11 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv12 = Conv_Bn_Activation(256, 512, 3, 1, 'leaky')\n",
    "        self.conv13 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv14 = Conv_Bn_Activation(256, 128, 1, 1, 'leaky')\n",
    "        # UP\n",
    "        self.upsample2 = Upsample()\n",
    "        # R 54\n",
    "        self.conv15 = Conv_Bn_Activation(256, 128, 1, 1, 'leaky')\n",
    "        # R -1 -3\n",
    "        self.conv16 = Conv_Bn_Activation(256, 128, 1, 1, 'leaky')\n",
    "        self.conv17 = Conv_Bn_Activation(128, 256, 3, 1, 'leaky')\n",
    "        self.conv18 = Conv_Bn_Activation(256, 128, 1, 1, 'leaky')\n",
    "        self.conv19 = Conv_Bn_Activation(128, 256, 3, 1, 'leaky')\n",
    "        self.conv20 = Conv_Bn_Activation(256, 128, 1, 1, 'leaky')\n",
    "\n",
    "    def forward(self, input, downsample4, downsample3, inference=False):\n",
    "        x1 = self.conv1(input)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x2)\n",
    "        # SPP\n",
    "        m1 = self.maxpool1(x3)\n",
    "        m2 = self.maxpool2(x3)\n",
    "        m3 = self.maxpool3(x3)\n",
    "        spp = torch.cat([m3, m2, m1, x3], dim=1)\n",
    "        # SPP end\n",
    "        x4 = self.conv4(spp)\n",
    "        x5 = self.conv5(x4)\n",
    "        x6 = self.conv6(x5)\n",
    "        x7 = self.conv7(x6)\n",
    "        # UP\n",
    "        up = self.upsample1(x7, downsample4.size(), self.inference)\n",
    "        # R 85\n",
    "        x8 = self.conv8(downsample4)\n",
    "        # R -1 -3\n",
    "        x8 = torch.cat([x8, up], dim=1)\n",
    "\n",
    "        x9 = self.conv9(x8)\n",
    "        x10 = self.conv10(x9)\n",
    "        x11 = self.conv11(x10)\n",
    "        x12 = self.conv12(x11)\n",
    "        x13 = self.conv13(x12)\n",
    "        x14 = self.conv14(x13)\n",
    "\n",
    "        # UP\n",
    "        up = self.upsample2(x14, downsample3.size(), self.inference)\n",
    "        # R 54\n",
    "        x15 = self.conv15(downsample3)\n",
    "        # R -1 -3\n",
    "        x15 = torch.cat([x15, up], dim=1)\n",
    "\n",
    "        x16 = self.conv16(x15)\n",
    "        x17 = self.conv17(x16)\n",
    "        x18 = self.conv18(x17)\n",
    "        x19 = self.conv19(x18)\n",
    "        x20 = self.conv20(x19)\n",
    "        return x20, x13, x6\n",
    "\n",
    "\n",
    "class Yolov4Head(nn.Module):\n",
    "    def __init__(self, output_ch, n_classes, inference=False):\n",
    "        super().__init__()\n",
    "        self.inference = inference\n",
    "\n",
    "        self.conv1 = Conv_Bn_Activation(128, 256, 3, 1, 'leaky')\n",
    "        self.conv2 = Conv_Bn_Activation(256, output_ch, 1, 1, 'linear', bn=False, bias=True)\n",
    "\n",
    "        self.yolo1 = YoloLayer(\n",
    "                                anchor_mask=[0, 1, 2], num_classes=n_classes,\n",
    "                                anchors=[12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401],\n",
    "                                num_anchors=9, stride=8)\n",
    "\n",
    "        # R -4\n",
    "        self.conv3 = Conv_Bn_Activation(128, 256, 3, 2, 'leaky')\n",
    "\n",
    "        # R -1 -16\n",
    "        self.conv4 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv5 = Conv_Bn_Activation(256, 512, 3, 1, 'leaky')\n",
    "        self.conv6 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv7 = Conv_Bn_Activation(256, 512, 3, 1, 'leaky')\n",
    "        self.conv8 = Conv_Bn_Activation(512, 256, 1, 1, 'leaky')\n",
    "        self.conv9 = Conv_Bn_Activation(256, 512, 3, 1, 'leaky')\n",
    "        self.conv10 = Conv_Bn_Activation(512, output_ch, 1, 1, 'linear', bn=False, bias=True)\n",
    "\n",
    "        self.yolo2 = YoloLayer(\n",
    "                                anchor_mask=[3, 4, 5], num_classes=n_classes,\n",
    "                                anchors=[12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401],\n",
    "                                num_anchors=9, stride=16)\n",
    "\n",
    "        # R -4\n",
    "        self.conv11 = Conv_Bn_Activation(256, 512, 3, 2, 'leaky')\n",
    "\n",
    "        # R -1 -37\n",
    "        self.conv12 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv13 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv14 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv15 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv16 = Conv_Bn_Activation(1024, 512, 1, 1, 'leaky')\n",
    "        self.conv17 = Conv_Bn_Activation(512, 1024, 3, 1, 'leaky')\n",
    "        self.conv18 = Conv_Bn_Activation(1024, output_ch, 1, 1, 'linear', bn=False, bias=True)\n",
    "\n",
    "        self.yolo3 = YoloLayer(\n",
    "                                anchor_mask=[6, 7, 8], num_classes=n_classes,\n",
    "                                anchors=[12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401],\n",
    "                                num_anchors=9, stride=32)\n",
    "\n",
    "    def forward(self, input1, input2, input3):\n",
    "        x1 = self.conv1(input1)\n",
    "        x2 = self.conv2(x1)\n",
    "\n",
    "        x3 = self.conv3(input1)\n",
    "        # R -1 -16\n",
    "        x3 = torch.cat([x3, input2], dim=1)\n",
    "        x4 = self.conv4(x3)\n",
    "        x5 = self.conv5(x4)\n",
    "        x6 = self.conv6(x5)\n",
    "        x7 = self.conv7(x6)\n",
    "        x8 = self.conv8(x7)\n",
    "        x9 = self.conv9(x8)\n",
    "        x10 = self.conv10(x9)\n",
    "\n",
    "        # R -4\n",
    "        x11 = self.conv11(x8)\n",
    "        # R -1 -37\n",
    "        x11 = torch.cat([x11, input3], dim=1)\n",
    "\n",
    "        x12 = self.conv12(x11)\n",
    "        x13 = self.conv13(x12)\n",
    "        x14 = self.conv14(x13)\n",
    "        x15 = self.conv15(x14)\n",
    "        x16 = self.conv16(x15)\n",
    "        x17 = self.conv17(x16)\n",
    "        x18 = self.conv18(x17)\n",
    "\n",
    "        if self.inference:\n",
    "            y1 = self.yolo1(x2)\n",
    "            y2 = self.yolo2(x10)\n",
    "            y3 = self.yolo3(x18)\n",
    "\n",
    "            return get_region_boxes([y1, y2, y3])\n",
    "\n",
    "        else:\n",
    "            return [x2, x10, x18]\n",
    "\n",
    "\n",
    "class Yolov4(nn.Module):\n",
    "    def __init__(self, yolov4conv137weight=None, n_classes=80, inference=False):\n",
    "        super().__init__()\n",
    "\n",
    "        output_ch = (4 + 1 + n_classes) * 3\n",
    "\n",
    "        # backbone\n",
    "        self.down1 = DownSample1()\n",
    "        self.down2 = DownSample2()\n",
    "        self.down3 = DownSample3()\n",
    "        self.down4 = DownSample4()\n",
    "        self.down5 = DownSample5()\n",
    "        # neck\n",
    "        self.neek = Neck(inference)\n",
    "        # yolov4conv137\n",
    "        if yolov4conv137weight:\n",
    "            _model = nn.Sequential(self.down1, self.down2, self.down3, self.down4, self.down5, self.neek)\n",
    "            pretrained_dict = torch.load(yolov4conv137weight)\n",
    "\n",
    "            model_dict = _model.state_dict()\n",
    "            # 1. filter out unnecessary keys\n",
    "            pretrained_dict = {k1: v for (k, v), k1 in zip(pretrained_dict.items(), model_dict)}\n",
    "            # 2. overwrite entries in the existing state dict\n",
    "            model_dict.update(pretrained_dict)\n",
    "            _model.load_state_dict(model_dict)\n",
    "\n",
    "        # head\n",
    "        self.head = Yolov4Head(output_ch, n_classes, inference)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        d1 = self.down1(input)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "\n",
    "        x20, x13, x6 = self.neek(d5, d4, d3)\n",
    "\n",
    "        output = self.head(x20, x13, x6)\n",
    "        return output\n",
    "\n",
    "\n",
    "def yolo_forward_dynamic(output, conf_thresh, num_classes, anchors, num_anchors, scale_x_y, only_objectness=1,\n",
    "                              validation=False):\n",
    "    # Output would be invalid if it does not satisfy this assert\n",
    "    # assert (output.size(1) == (5 + num_classes) * num_anchors)\n",
    "\n",
    "    # print(output.size())\n",
    "\n",
    "    # Slice the second dimension (channel) of output into:\n",
    "    # [ 2, 2, 1, num_classes, 2, 2, 1, num_classes, 2, 2, 1, num_classes ]\n",
    "    # And then into\n",
    "    # bxy = [ 6 ] bwh = [ 6 ] det_conf = [ 3 ] cls_conf = [ num_classes * 3 ]\n",
    "    # batch = output.size(0)\n",
    "    # H = output.size(2)\n",
    "    # W = output.size(3)\n",
    "\n",
    "    bxy_list = []\n",
    "    bwh_list = []\n",
    "    det_confs_list = []\n",
    "    cls_confs_list = []\n",
    "\n",
    "    for i in range(num_anchors):\n",
    "        begin = i * (5 + num_classes)\n",
    "        end = (i + 1) * (5 + num_classes)\n",
    "\n",
    "        bxy_list.append(output[:, begin : begin + 2])\n",
    "        bwh_list.append(output[:, begin + 2 : begin + 4])\n",
    "        det_confs_list.append(output[:, begin + 4 : begin + 5])\n",
    "        cls_confs_list.append(output[:, begin + 5 : end])\n",
    "\n",
    "    # Shape: [batch, num_anchors * 2, H, W]\n",
    "    bxy = torch.cat(bxy_list, dim=1)\n",
    "    # Shape: [batch, num_anchors * 2, H, W]\n",
    "    bwh = torch.cat(bwh_list, dim=1)\n",
    "\n",
    "    # Shape: [batch, num_anchors, H, W]\n",
    "    det_confs = torch.cat(det_confs_list, dim=1)\n",
    "    # Shape: [batch, num_anchors * H * W]\n",
    "    det_confs = det_confs.view(output.size(0), num_anchors * output.size(2) * output.size(3))\n",
    "\n",
    "    # Shape: [batch, num_anchors * num_classes, H, W]\n",
    "    cls_confs = torch.cat(cls_confs_list, dim=1)\n",
    "    # Shape: [batch, num_anchors, num_classes, H * W]\n",
    "    cls_confs = cls_confs.view(output.size(0), num_anchors, num_classes, output.size(2) * output.size(3))\n",
    "    # Shape: [batch, num_anchors, num_classes, H * W] --> [batch, num_anchors * H * W, num_classes]\n",
    "    cls_confs = cls_confs.permute(0, 1, 3, 2).reshape(output.size(0), num_anchors * output.size(2) * output.size(3), num_classes)\n",
    "\n",
    "    # Apply sigmoid(), exp() and softmax() to slices\n",
    "    #\n",
    "    bxy = torch.sigmoid(bxy) * scale_x_y - 0.5 * (scale_x_y - 1)\n",
    "    bwh = torch.exp(bwh)\n",
    "    det_confs = torch.sigmoid(det_confs)\n",
    "    cls_confs = torch.sigmoid(cls_confs)\n",
    "\n",
    "    # Prepare C-x, C-y, P-w, P-h (None of them are torch related)\n",
    "    grid_x = np.expand_dims(np.expand_dims(np.expand_dims(np.linspace(0, output.size(3) - 1, output.size(3)), axis=0).repeat(output.size(2), 0), axis=0), axis=0)\n",
    "    grid_y = np.expand_dims(np.expand_dims(np.expand_dims(np.linspace(0, output.size(2) - 1, output.size(2)), axis=1).repeat(output.size(3), 1), axis=0), axis=0)\n",
    "    # grid_x = torch.linspace(0, W - 1, W).reshape(1, 1, 1, W).repeat(1, 1, H, 1)\n",
    "    # grid_y = torch.linspace(0, H - 1, H).reshape(1, 1, H, 1).repeat(1, 1, 1, W)\n",
    "\n",
    "    anchor_w = []\n",
    "    anchor_h = []\n",
    "    for i in range(num_anchors):\n",
    "        anchor_w.append(anchors[i * 2])\n",
    "        anchor_h.append(anchors[i * 2 + 1])\n",
    "\n",
    "    device = None\n",
    "    cuda_check = output.is_cuda\n",
    "    if cuda_check:\n",
    "        device = output.get_device()\n",
    "\n",
    "    bx_list = []\n",
    "    by_list = []\n",
    "    bw_list = []\n",
    "    bh_list = []\n",
    "\n",
    "    # Apply C-x, C-y, P-w, P-h\n",
    "    for i in range(num_anchors):\n",
    "        ii = i * 2\n",
    "        # Shape: [batch, 1, H, W]\n",
    "        bx = bxy[:, ii : ii + 1] + torch.tensor(grid_x, device=device, dtype=torch.float32) # grid_x.to(device=device, dtype=torch.float32)\n",
    "        # Shape: [batch, 1, H, W]\n",
    "        by = bxy[:, ii + 1 : ii + 2] + torch.tensor(grid_y, device=device, dtype=torch.float32) # grid_y.to(device=device, dtype=torch.float32)\n",
    "        # Shape: [batch, 1, H, W]\n",
    "        bw = bwh[:, ii : ii + 1] * anchor_w[i]\n",
    "        # Shape: [batch, 1, H, W]\n",
    "        bh = bwh[:, ii + 1 : ii + 2] * anchor_h[i]\n",
    "\n",
    "        bx_list.append(bx)\n",
    "        by_list.append(by)\n",
    "        bw_list.append(bw)\n",
    "        bh_list.append(bh)\n",
    "\n",
    "\n",
    "    ########################################\n",
    "    #   Figure out bboxes from slices     #\n",
    "    ########################################\n",
    "\n",
    "    # Shape: [batch, num_anchors, H, W]\n",
    "    bx = torch.cat(bx_list, dim=1)\n",
    "    # Shape: [batch, num_anchors, H, W]\n",
    "    by = torch.cat(by_list, dim=1)\n",
    "    # Shape: [batch, num_anchors, H, W]\n",
    "    bw = torch.cat(bw_list, dim=1)\n",
    "    # Shape: [batch, num_anchors, H, W]\n",
    "    bh = torch.cat(bh_list, dim=1)\n",
    "\n",
    "    # Shape: [batch, 2 * num_anchors, H, W]\n",
    "    bx_bw = torch.cat((bx, bw), dim=1)\n",
    "    # Shape: [batch, 2 * num_anchors, H, W]\n",
    "    by_bh = torch.cat((by, bh), dim=1)\n",
    "\n",
    "    # normalize coordinates to [0, 1]\n",
    "    bx_bw /= output.size(3)\n",
    "    by_bh /= output.size(2)\n",
    "\n",
    "    # Shape: [batch, num_anchors * H * W, 1]\n",
    "    bx = bx_bw[:, :num_anchors].view(output.size(0), num_anchors * output.size(2) * output.size(3), 1)\n",
    "    by = by_bh[:, :num_anchors].view(output.size(0), num_anchors * output.size(2) * output.size(3), 1)\n",
    "    bw = bx_bw[:, num_anchors:].view(output.size(0), num_anchors * output.size(2) * output.size(3), 1)\n",
    "    bh = by_bh[:, num_anchors:].view(output.size(0), num_anchors * output.size(2) * output.size(3), 1)\n",
    "\n",
    "    bx1 = bx - bw * 0.5\n",
    "    by1 = by - bh * 0.5\n",
    "    bx2 = bx1 + bw\n",
    "    by2 = by1 + bh\n",
    "\n",
    "    # Shape: [batch, num_anchors * h * w, 4] -> [batch, num_anchors * h * w, 1, 4]\n",
    "    boxes = torch.cat((bx1, by1, bx2, by2), dim=2).view(output.size(0), num_anchors * output.size(2) * output.size(3), 1, 4)\n",
    "    # boxes = boxes.repeat(1, 1, num_classes, 1)\n",
    "\n",
    "    # boxes:     [batch, num_anchors * H * W, 1, 4]\n",
    "    # cls_confs: [batch, num_anchors * H * W, num_classes]\n",
    "    # det_confs: [batch, num_anchors * H * W]\n",
    "\n",
    "    det_confs = det_confs.view(output.size(0), num_anchors * output.size(2) * output.size(3), 1)\n",
    "    confs = cls_confs * det_confs\n",
    "\n",
    "    # boxes: [batch, num_anchors * H * W, 1, 4]\n",
    "    # confs: [batch, num_anchors * H * W, num_classes]\n",
    "\n",
    "    return  boxes, confs\n",
    "\n",
    "class YoloLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Yolo layer\n",
    "    model_out: while inference,is post-processing inside or outside the model\n",
    "        true:outside\n",
    "    \"\"\"\n",
    "    def __init__(self, anchor_mask=[], num_classes=0, anchors=[], num_anchors=1, stride=32, model_out=False):\n",
    "        super(YoloLayer, self).__init__()\n",
    "        self.anchor_mask = anchor_mask\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        self.num_anchors = num_anchors\n",
    "        self.anchor_step = len(anchors) // num_anchors\n",
    "        self.coord_scale = 1\n",
    "        self.noobject_scale = 1\n",
    "        self.object_scale = 5\n",
    "        self.class_scale = 1\n",
    "        self.thresh = 0.6\n",
    "        self.stride = stride\n",
    "        self.seen = 0\n",
    "        self.scale_x_y = 1\n",
    "\n",
    "        self.model_out = model_out\n",
    "\n",
    "    def forward(self, output, target=None):\n",
    "        if self.training:\n",
    "            return output\n",
    "        masked_anchors = []\n",
    "        for m in self.anchor_mask:\n",
    "            masked_anchors += self.anchors[m * self.anchor_step:(m + 1) * self.anchor_step]\n",
    "        masked_anchors = [anchor / self.stride for anchor in masked_anchors]\n",
    "\n",
    "        return yolo_forward_dynamic(output, self.thresh, self.num_classes, masked_anchors, len(self.anchor_mask),scale_x_y=self.scale_x_y)\n",
    "\n",
    "\n",
    "def get_region_boxes(boxes_and_confs):\n",
    "\n",
    "    # print('Getting boxes from boxes and confs ...')\n",
    "\n",
    "    boxes_list = []\n",
    "    confs_list = []\n",
    "\n",
    "    for item in boxes_and_confs:\n",
    "        boxes_list.append(item[0])\n",
    "        confs_list.append(item[1])\n",
    "\n",
    "    # boxes: [batch, num1 + num2 + num3, 1, 4]\n",
    "    # confs: [batch, num1 + num2 + num3, num_classes]\n",
    "    boxes = torch.cat(boxes_list, dim=1)\n",
    "    confs = torch.cat(confs_list, dim=1)\n",
    "\n",
    "    return boxes, confs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the COCO 2017 Evaluation dataset and define the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO http://images.cocodataset.org/zips/val2017.zip\n",
    "!curl -LO http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip -q val2017.zip\n",
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "def get_image_filenames(root=os.getcwd()):\n",
    "    \"\"\"\n",
    "    Generate paths to the coco dataset image files.\n",
    "\n",
    "    Args:\n",
    "        root (str): The root folder contains.\n",
    "\n",
    "    Yields:\n",
    "        filename (str): The path to an image file.\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(root, 'val2017')\n",
    "    for root, dirs, files in os.walk(image_path):\n",
    "        for filename in files:\n",
    "            yield os.path.join(image_path, filename)\n",
    "\n",
    "\n",
    "def get_coco_dataloader(coco2017_root, transform, subset_indices=None):\n",
    "    \"\"\"\n",
    "    Create the dataset loader and ground truth coco dataset.\n",
    "\n",
    "    Arguments:\n",
    "        coco2017_root (str): The root directory to load the data/labels from.\n",
    "        transform (torchvision.Transform): A transform to apply to the images.\n",
    "        subset_indices (list): Indices used to create a subset of the dataset.\n",
    "\n",
    "    Returns:\n",
    "        loader (iterable): Produces transformed images and labels.\n",
    "        cocoGt (pycocotools.coco.COCO): Contains the ground truth in coco\n",
    "            format.\n",
    "        label_info (dict): A mapping from label id to the human-readable name.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the dataset\n",
    "    coco2017_img_path = os.path.join(coco2017_root, 'val2017')\n",
    "    coco2017_ann_path = os.path.join(\n",
    "        coco2017_root, 'annotations/instances_val2017.json')\n",
    "\n",
    "    # check the number of images in val2017 - Should be 5000\n",
    "    num_files = len(list(get_image_filenames(coco2017_root)))\n",
    "    print('\\nNumber of images in val2017 = {}\\n'.format(num_files))\n",
    "\n",
    "    # load annotations to decode classification results\n",
    "    with open(coco2017_ann_path) as f:\n",
    "        annotate_json = json.load(f)\n",
    "    label_info = {label[\"id\"]: label[\"name\"]\n",
    "                  for label in annotate_json['categories']}\n",
    "\n",
    "    # initialize COCO ground truth dataset\n",
    "    cocoGt = COCO(coco2017_ann_path)\n",
    "\n",
    "    # create the dataset using torchvision's coco detection dataset\n",
    "    coco_val_data = dset.CocoDetection(\n",
    "        root=coco2017_img_path,\n",
    "        annFile=coco2017_ann_path,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    if subset_indices is not None:\n",
    "        # Create a smaller subset of the data for testing - e.g. to pinpoint error at image 516\n",
    "        coco_val_data = torch.utils.data.Subset(coco_val_data, subset_indices)\n",
    "\n",
    "    # create the dataloader using torch dataloader\n",
    "    loader = torch.utils.data.DataLoader(coco_val_data, batch_size=1, shuffle=False)\n",
    "\n",
    "    return loader, cocoGt, label_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco2017_root = './'\n",
    "orig_coco_val_data_loader, cocoGt, label_info = get_coco_dataloader(coco2017_root, transforms.ToTensor())\n",
    "transform = transforms.Compose([transforms.Resize([608, 608]), transforms.ToTensor()])\n",
    "coco_val_data_loader, cocoGt, label_info = get_coco_dataloader(coco2017_root, transform)\n",
    "image_orig, _ = next(iter(orig_coco_val_data_loader))\n",
    "print(image_orig.shape)\n",
    "image, image_info = next(iter(coco_val_data_loader))\n",
    "image_id = image_info[0][\"image_id\"].item()\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pre-trained model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params={'id': id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {'id': id, 'confirm': token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, destination)\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file_from_google_drive('1wv_LiFeCRYwtpkqREPeI13-gPELBDwuJ', './yolo_v4.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model and load pretrained checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov4(yolov4conv137weight=None, n_classes=80, inference=True)\n",
    "weightfile = \"./yolo_v4.pth\"\n",
    "pretrained_dict = torch.load(weightfile, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(pretrained_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [1,3,608,608]\n",
    "trace = torch.jit.trace(model.float().eval(), torch.zeros(input_shape).float())\n",
    "trace.save('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf v2-yolo-model.tar.gz model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up some files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm annotations_trainval2017.zip\n",
    "!rm val2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the pre-trained checkpoint to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client('sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'v2-yolo-model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = sess.upload_data(path=model_filename, key_prefix='models')\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model with SageMaker Neo & package model with SageMaker Edge Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where your model is stored\n",
    "s3_model_uri = 's3://{}/models/{}'.format(bucket, model_filename)\n",
    "\n",
    "# Store compiled model in S3 within the 'compiled_models' directory\n",
    "compilation_output_dir = 'compiled_models'\n",
    "compiled_output_location = 's3://{}/{}'.format(bucket, compilation_output_dir)\n",
    "\n",
    "# Store packaged model in S3 within the 'packaged_models' directory\n",
    "packaged_output_dir = 'packaged_models'\n",
    "packaged_output_location = 's3://{}/{}'.format(bucket, packaged_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework information\n",
    "framework = 'PYTORCH'\n",
    "framework_version = '1.6'\n",
    "\n",
    "input_shape = [1,3,608,608]\n",
    "input_layer_name = 'input0'\n",
    "data_shape = json.dumps({input_layer_name: input_shape})\n",
    "\n",
    "model_name = 'v2-yolo-model'\n",
    "model_version = '1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we compile the YoloV4 model to run on a C5 EC2 instance (Linux OS, x86_64 arch, Skylake AVX512). A list of supported target architecture types can be found here: https://docs.aws.amazon.com/sagemaker/latest/dg/neo-supported-devices-edge-devices.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation job with unique job ID\n",
    "from sagemaker.utils import name_from_base\n",
    "compilation_job_name = name_from_base('torch-yolov4-neo')\n",
    "\n",
    "sm_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': s3_model_uri,\n",
    "        'DataInputConfig': data_shape,\n",
    "        'Framework': framework,\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': compiled_output_location,\n",
    "        'TargetPlatform': { 'Os': 'LINUX', 'Arch': 'X86_64' },\n",
    "        'CompilerOptions': \"{ 'mcpu': 'skylake-avx512'}\"\n",
    "    },\n",
    "    StoppingCondition={ 'MaxRuntimeInSeconds': 900 }    \n",
    ")\n",
    "while True:\n",
    "    resp = sm_client.describe_compilation_job(CompilationJobName=compilation_job_name)    \n",
    "    if resp['CompilationJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['CompilationJobStatus'], compilation_job_name)\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packaging job with unique job ID\n",
    "edge_packaging_job_name = name_from_base('torch-yolov4-neo')\n",
    "\n",
    "resp = sm_client.create_edge_packaging_job(\n",
    "    EdgePackagingJobName=edge_packaging_job_name,\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    ModelName=model_name,\n",
    "    ModelVersion=model_version,\n",
    "    RoleArn=role,\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': packaged_output_location\n",
    "    }\n",
    ")\n",
    "while True:\n",
    "    resp = sm_client.describe_edge_packaging_job(EdgePackagingJobName=edge_packaging_job_name)    \n",
    "    if resp['EdgePackagingJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['EdgePackagingJobStatus'], compilation_job_name)        \n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate IoT Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, verify that your SageMaker Execution role has the appropriate IoT permissions:\n",
    " - iot:CreateThing\n",
    " - iot:CreateThingType\n",
    " - iot:CreateKeysAndCertificate\n",
    " - iot:DescribeRoleAlias\n",
    " - iot:CreatePolicy\n",
    " - iot:AttachPolicy\n",
    " - iot:DescribeEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iot_client = boto3.client(\"iot\")\n",
    "\n",
    "iot_thing_name = \"sample-iot-thing\"\n",
    "iot_thing_type = \"sample-iot-thing-type\"\n",
    "\n",
    "iot_client.create_thing_type(\n",
    "    thingTypeName=iot_thing_type\n",
    ")\n",
    "\n",
    "# Create an AWS IoT thing objects\n",
    "iot_client.create_thing(\n",
    "    thingName=iot_thing_name,\n",
    "    thingTypeName=iot_thing_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Make sure to enter your IoT SageMaker role ARN below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_fleet_name=\"sample-device-fleet\"\n",
    "fleet_role=\"<ENTER SAGEMAKER IOT ROLE ARN HERE>\" # https://docs.aws.amazon.com/sagemaker/latest/dg/edge-getting-started-step1.html\n",
    "device_output_bucket=f\"s3://{bucket}/device_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.create_device_fleet(\n",
    "    DeviceFleetName=device_fleet_name,\n",
    "    RoleArn=fleet_role,\n",
    "    Description=\"fleet description\",\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': device_output_bucket\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name=\"sample-device\"\n",
    "description=\"Device 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.register_devices(\n",
    "    DeviceFleetName=device_fleet_name,\n",
    "    Devices=[\n",
    "        {          \n",
    "            \"DeviceName\": device_name,\n",
    "            \"IotThingName\": iot_thing_name,\n",
    "            \"Description\": description\n",
    "        }\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 2048-bit RSA key pair and issues an X.509 # certificate \n",
    "# using the issued public key.\n",
    "create_cert = iot_client.create_keys_and_certificate(\n",
    "    setAsActive=True \n",
    ")\n",
    "\n",
    "# Get certificate from dictionary object and save in its own\n",
    "with open('./device.pem.crt', 'w') as f:\n",
    "    for line in create_cert['certificatePem'].split('\\n'):\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n",
    "# Get private key from dictionary object and save in its own \n",
    "with open('./private.pem.key', 'w') as f:\n",
    "    for line in create_cert['keyPair']['PrivateKey'].split('\\n'):\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n",
    "# Get a private key from dictioanary object and save in its own \n",
    "with open('./public.pem.key', 'w') as f:\n",
    "    for line in create_cert['keyPair']['PublicKey'].split('\\n'):\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Amazon Resource Name (ARN) and alias that has access \n",
    "# to AWS Internet of Things (IoT).\n",
    "sm_client.describe_device_fleet(DeviceFleetName=device_fleet_name)\n",
    "\n",
    "# Store iot role alias string in a variable\n",
    "# Grabs role ARN\n",
    "full_role_alias_name = sm_client.describe_device_fleet(DeviceFleetName=device_fleet_name)['IotRoleAlias']\n",
    "start_index = full_role_alias_name.find('SageMaker') # Find beginning of role name  \n",
    "role_alias_name = full_role_alias_name[start_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_alias = iot_client.describe_role_alias(\n",
    "                    roleAlias=role_alias_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_policy = {\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": {\n",
    "    \"Effect\": \"Allow\",\n",
    "    \"Action\": \"iot:AssumeRoleWithCertificate\",\n",
    "    \"Resource\": role_alias['roleAliasDescription']['roleAliasArn']\n",
    "  }\n",
    "}\n",
    "\n",
    "policy_name = 'aliaspolicy-'+ str(time.time()).split('.')[0]\n",
    "aliaspolicy = iot_client.create_policy(policyName=policy_name,\n",
    "                                       policyDocument=json.dumps(alias_policy))\n",
    "\n",
    "# Attach policy\n",
    "iot_client.attach_policy(policyName=policy_name,\n",
    "                            target=create_cert['certificateArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique endpoint specific to your AWS account that is making the call.\n",
    "iot_endpoint = iot_client.describe_endpoint(\n",
    "    endpointType='iot:CredentialProvider'\n",
    ")\n",
    "\n",
    "endpoint=\"https://{}/role-aliases/{}/credentials\".format(iot_endpoint['endpointAddress'],role_alias_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.amazontrust.com/repository/AmazonRootCA1.pem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl --cert device.pem.crt --key private.pem.key --cacert AmazonRootCA1.pem $endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp private.pem.key s3://{bucket}/authorization-files/\n",
    "!aws s3 cp device.pem.crt s3://{bucket}/authorization-files/\n",
    "!aws s3 cp AmazonRootCA1.pem s3://{bucket}/authorization-files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & configure SageMaker Edge Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_version=\"1.20210512.96da6cc\"\n",
    "agent_arch=\"linux-x64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-edge-release-store-{region}-{agent_arch}/Releases/{agent_version}/{agent_version}.tgz ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-edge-release-store-{region}-{agent_arch}/Certificates/{region}/{region}.pem ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {region}.pem s3://{bucket}/authorization-files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_edge_config = {\n",
    "    \"sagemaker_edge_core_device_name\": device_name,\n",
    "    \"sagemaker_edge_core_device_fleet_name\": device_fleet_name,\n",
    "    \"sagemaker_edge_core_capture_data_buffer_size\": 30,\n",
    "    \"sagemaker_edge_core_capture_data_push_period_seconds\": 4,\n",
    "    \"sagemaker_edge_core_folder_prefix\": \"demo_capture\",\n",
    "    \"sagemaker_edge_core_region\": region,\n",
    "    \"sagemaker_edge_core_root_certs_path\": \"/home/agent/certs/root\",\n",
    "    \"sagemaker_edge_provider_aws_ca_cert_file\": \"/home/agent/certs/iot/AmazonRootCA1.pem\",\n",
    "    \"sagemaker_edge_provider_aws_cert_file\": \"/home/agent/certs/iot/device.pem.crt\",\n",
    "    \"sagemaker_edge_provider_aws_cert_pk_file\": \"/home/agent/certs/iot/private.pem.key\",\n",
    "    \"sagemaker_edge_provider_aws_iot_cred_endpoint\": endpoint,\n",
    "    \"sagemaker_edge_provider_provider\": \"Aws\",\n",
    "    \"sagemaker_edge_provider_s3_bucket_name\": bucket,\n",
    "    \"sagemaker_edge_core_capture_data_destination\": \"Cloud\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_config_file = open(\"agent.json\", \"w\")\n",
    "json.dump(sagemaker_edge_config, edge_config_file, indent = 6)\n",
    "edge_config_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Edge Agent Deployment Package set-up\n",
    "\n",
    "Now that we have the required files for the edge agent to interact with the cloud, we can create the correct directory structure and zip up the files for use when building our Docker container. The directory structure should match the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "agent\n",
    "certs\n",
    "     root\n",
    "     |     <<aws_region>>.pem # CA certificate used by Edge Manager to sign the model\n",
    "     |\n",
    "     iot\n",
    "           device.pem.crt    # IoT Certificate\n",
    "           AmazonRootCA1.pem # IoT Public Key\n",
    "           private.pem.key   # IoT Private Key\n",
    "           \n",
    "conf\n",
    "      agent.json # Edge Manager config file\n",
    "      \n",
    "models\n",
    "    <<device_id>>\n",
    "        <<model_name>>\n",
    "            <<model_version>> # Artifacts from the Edge Manager model package\n",
    "                  sagemaker_edge.manifest\n",
    "                  ...\n",
    "\n",
    "app # Client API stubs\n",
    "      agent_pb2_grpc.py\n",
    "      agent_pb2.py\n",
    "\n",
    "artifacts # Agent artifacts\n",
    "    bin\n",
    "    docs\n",
    "    \n",
    "Dockerfile\n",
    "build.sh\n",
    "<<agent_version>>.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir agent\n",
    "!mkdir agent/app\n",
    "!mkdir agent/artifacts\n",
    "!mkdir agent/certs\n",
    "!mkdir agent/certs/root\n",
    "!mkdir agent/certs/iot\n",
    "!mkdir agent/conf\n",
    "!mkdir agent/models\n",
    "!mkdir agent/models/{device_name}\n",
    "!mkdir agent/models/{device_name}/{model_name}\n",
    "!mkdir agent/models/{device_name}/{model_name}/{model_version}\n",
    "\n",
    "!mv AmazonRootCA1.pem agent/certs/iot/\n",
    "!mv device.pem.crt agent/certs/iot/\n",
    "!mv private.pem.key agent/certs/iot/\n",
    "\n",
    "!mv {region}.pem agent/certs/root/\n",
    "\n",
    "!mv agent.json agent/conf/\n",
    "\n",
    "!mv {agent_version}.tgz agent/\n",
    "!tar -zxf agent/{agent_version}.tgz -C agent/artifacts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build client API stubs\n",
    "\n",
    "Let's extract the edge agent from the tgz file and generate the client API stubs that our driver application will use to interact with the model via gRPC or Shared Memory. For more details on the API definition, please visit the documentation here: https://docs.aws.amazon.com/sagemaker/latest/dg/edge-manage-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by using protoc, we can generate stubs (client api) for connecting to the agent and invoking its API\n",
    "!python3 -m grpc_tools.protoc --proto_path=agent/artifacts/docs/api --python_out=agent/app/ --grpc_python_out=agent/app/ agent/artifacts/docs/api/agent.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the artifacts directory for now since our Docker build process will take care of downloading the agent artifacts for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf agent/artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's zip up this main part of the deployment package and upload it to S3. Then, we are ready to download the artifacts and build our agent container. You can either do this locally or as part of your container pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_package_name='agent_deployment_package.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf {deployment_package_name} agent --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_deployment_path = sess.upload_data(path=deployment_package_name, key_prefix='agent_deployment')\n",
    "print(agent_deployment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 mv s3://{bucket}/packaged_models/{model_name}-{model_version}.tar.gz s3://{bucket}/agent_deployment/{model_name}-{model_version}.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete the remaining steps locally or in your container build pipeline\n",
    "The remaining steps require Docker to build the container images for the edge agent and the driver application. Follow the repo README for instructions for the remaining steps."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}